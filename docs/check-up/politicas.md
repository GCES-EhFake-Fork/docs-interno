# Pol√≠ticas da comunidade

## Governan√ßa

A comunidade **EH FAKE** possui uma estrutura de governan√ßa simplificada, com um √∫nico mantenedor principal:

**üîß Mantenedor Principal:**

- **Leonardo Lago Moreno** ([lelamo2002](https://github.com/lelamo2002))

### Estrutura de Governan√ßa

Atualmente, **n√£o h√° pap√©is formalmente definidos** na governan√ßa da comunidade. O projeto adota um modelo colaborativo onde:

- O mantenedor principal possui responsabilidades de supervis√£o geral
- Os membros contribuidores agora ter√£o **acesso direto ao reposit√≥rio base** (sem necessidade de fork para contribui√ß√µes)
- Decis√µes t√©cnicas s√£o tomadas de forma colaborativa atrav√©s de discuss√µes em issues e pull requests
- A comunidade est√° em processo de crescimento e formaliza√ß√£o de estruturas organizacionais

### Organiza√ß√£o do C√≥digo

![arquitetura do projeto](https://eh-fake.github.io/docs/assets/diagrama-pipeline.png)

- **Spiders**: Web Crawlers que coletam as URL's de artigos/not√≠cias presentes em sites de not√≠cias e guardam esses links no banco de dados.

- **Plays**: Web Scrappers que acessam as URL's coletadas pelas Spiders e extraem o conte√∫do da p√°gina.

- **Estrutura√ß√£o dos dados**: O conte√∫do da p√°gina extra√≠do √© armazenado de forma estruturada utilizando PostgreSQL.

  - MinIO: Armazenamento de screenshots e arquivos de m√≠dia obtidos no scrapping (descontinuado)

- **API REST**: Fornece os dados coletados por meio de requisi√ß√µes HTTP

- **Interface web**: Visualiza√ß√£o dos dados em uma p√°gina web.

**ESTRUTURA DE PASTAS**

```text
check-up/
‚îú‚îÄ‚îÄ plays/       # L√≥gicas espec√≠ficas de coleta
‚îú‚îÄ‚îÄ spiders/     # Crawlers (spiders)
‚îú‚îÄ‚îÄ tests/       # Testes com Pytest
‚îú‚îÄ‚îÄ utils/       # Fun√ß√µes utilit√°rias
‚îú‚îÄ‚îÄ web/
‚îÇ   ‚îú‚îÄ‚îÄ server/  # Backend FastAPI
‚îÇ   ‚îî‚îÄ‚îÄ client/  # Frontend React
‚îî‚îÄ‚îÄ Makefile     # Scripts de automa√ß√£o
```

### Fluxo de Contribui√ß√£o

O projeto CheckUp adota um modelo de contribui√ß√£o baseado em issues estruturadas e pull requests. O processo √© dividido em etapas bem definidas para garantir qualidade e consist√™ncia:

#### 1. Abertura de Issue

Toda contribui√ß√£o deve come√ßar com a **abertura de uma issue** utilizando um dos templates padronizados disponibilizados pela comunidade:

- **üÜï Novo Scraper de Portal**: Para cria√ß√£o de scrapers completamente novos
- **üîß Adaptar Scraper Existente**: Para adapta√ß√£o de scrapers j√° existentes
- **üêõ Corre√ß√£o de Bug**: Para reportar e corrigir problemas identificados

Cada template possui campos espec√≠ficos que devem ser preenchidos, incluindo informa√ß√µes t√©cnicas sobre o portal, URLs de teste e crit√©rios de aceita√ß√£o detalhados.

#### 2. Fork e Clone do Projeto

Ap√≥s a cria√ß√£o da issue, o contribuidor deve:

1. **Forkar o reposit√≥rio** para sua conta pessoal no GitHub
2. **Clonar o fork** para sua m√°quina local de desenvolvimento
3. Criar uma **branch espec√≠fica** para a funcionalidade/corre√ß√£o

#### 3. Desenvolvimento e Implementa√ß√£o

O contribuidor ir√° codificar a funcionalidade seguindo os padr√µes estabelecidos:

- **Para novos scrapers**: Implementar tanto o Spider (coleta de URLs) quanto o Play (extra√ß√£o de conte√∫do)
- **Para adapta√ß√µes**: Atualizar seletores e remover funcionalidades obsoletas
- **Para corre√ß√µes**: Identificar e resolver o problema reportado

#### 4. Testes e Valida√ß√£o

Antes de submeter a contribui√ß√£o, √© obrigat√≥rio testar a funcionalidade contra os **crit√©rios de aceita√ß√£o** definidos na issue original.

#### 5. Pull Request

Ap√≥s valida√ß√£o local, o contribuidor deve abrir uma **Pull Request (PR)** para o reposit√≥rio base, que ser√° analisada pelos mantenedores do projeto.

### Crit√©rios de Aceita√ß√£o

Os crit√©rios de aceita√ß√£o variam conforme o tipo de contribui√ß√£o:

#### Para Novos Scrapers:

- **Extra√ß√£o Completa**: Deve extrair obrigatoriamente 4 campos:

  - T√≠tulo da not√≠cia
  - Descri√ß√£o/subt√≠tulo (quando dispon√≠vel)
  - Corpo completo do texto
  - Tags/categorias associadas

- **Estrutura T√©cnica**:

  - Spider herda de `BaseSpider` e implementa filtragem adequada via `allow_url()`
  - Play herda de `BasePlay` e implementa m√©todo `match()`
  - Coleta apenas URLs da p√°gina inicial (sem crawling recursivo)
  - Retorna `EntryItem` com todos os campos preenchidos

- **Valida√ß√£o**:
  - Testado com 5-10 URLs reais fornecidas na issue
  - Pipeline completo funcional (`make crawl_[nome]` + `make scrape_[nome]`)
  - Dados salvos corretamente no PostgreSQL
  - Aus√™ncia de erros cr√≠ticos nos logs

#### Para Adapta√ß√µes de Scrapers Existentes:

- **Atualiza√ß√£o de Seletores**: Re-inspe√ß√£o do portal e atualiza√ß√£o de seletores CSS/XPath
- **Remo√ß√£o de C√≥digo Obsoleto**: Elimina√ß√£o de funcionalidades descontinuadas (ex: screenshots)
- **Implementa√ß√£o de Novos Campos**: Adi√ß√£o de extra√ß√£o de descri√ß√£o e tags
- **Filtragem Aprimorada**: Garantia de coleta apenas de URLs de not√≠cias v√°lidas

#### Para Corre√ß√µes de Bug:

- **Reprodu√ß√£o do Problema**: Demonstra√ß√£o clara do bug identificado
- **Solu√ß√£o Efetiva**: Corre√ß√£o que resolve o problema sem introduzir regress√µes
- **Testes de Valida√ß√£o**: Verifica√ß√£o de que a corre√ß√£o funciona nos cen√°rios reportados

## Qualidade

A comunidade CheckUp mant√©m rigorosos padr√µes de qualidade atrav√©s de pol√≠ticas bem definidas para c√≥digo, testes e integra√ß√£o cont√≠nua.

### Padr√µes de C√≥digo

#### Conven√ß√£o de Branches

O projeto adota o **Git Flow** como modelo de ramifica√ß√£o, garantindo entregas organizadas e releases controladas:

- **`main`**: C√≥digo est√°vel em produ√ß√£o
- **`develop`**: Integra√ß√£o cont√≠nua de funcionalidades
- **`feature/*`**: Desenvolvimento de novas funcionalidades (`feature/<issue>-<slug>`)
- **`bugfix/*`**: Corre√ß√µes durante desenvolvimento (`bugfix/<issue>-<slug>`)
- **`release/*`**: Prepara√ß√£o de vers√µes (`release/vX.Y.Z`)
- **`hotfix/*`**: Corre√ß√µes cr√≠ticas em produ√ß√£o (`hotfix/vX.Y.Z`)

#### Conven√ß√£o de Commits

Baseada na especifica√ß√£o **Conventional Commits v1.0.0**, seguindo o padr√£o:

```
<tipo>(<escopo opcional>): <t√≠tulo no imperativo>

<corpo explicativo opcional>

<rodap√© com BREAKING CHANGE e/ou refer√™ncias de issue>
```

**Tipos de commit permitidos:**

- `feat`: Nova funcionalidade
- `fix`: Corre√ß√£o de bugs
- `docs`: Atualiza√ß√µes de documenta√ß√£o
- `style`: Formata√ß√£o e estilo de c√≥digo
- `refactor`: Refatora√ß√µes sem mudan√ßa de comportamento
- `test`: Cria√ß√£o ou modifica√ß√£o de testes
- `perf`: Melhorias de performance
- `build`: Mudan√ßas no sistema de build
- `ci/cd`: Configura√ß√µes de integra√ß√£o/entrega cont√≠nua

#### Lint e Formata√ß√£o

- **Python**: Flake8 com configura√ß√µes espec√≠ficas para o projeto
- **Frontend**: Biome para linting e formata√ß√£o autom√°tica
- **Linha m√°xima**: 150 caracteres
- **Valida√ß√£o autom√°tica** em todos os Pull Requests

### Implementa√ß√£o de Testes

#### Estrutura de Testes

```text
tests/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ plays/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_base.py      # Testes para classe base
‚îÇ   ‚îî‚îÄ‚îÄ test_uol.py       # Testes espec√≠ficos por portal
‚îî‚îÄ‚îÄ [outros m√≥dulos de teste]
```

#### Tipos de Testes Implementados

**1. Testes Unit√°rios (Pytest)**

- Valida√ß√£o de extra√ß√£o de conte√∫do por portal
- Testes de filtragem de URLs
- Verifica√ß√£o de seletores CSS/XPath
- Valida√ß√£o de dados extra√≠dos (t√≠tulo, descri√ß√£o, corpo, tags)

**2. Testes de Integra√ß√£o**

- Pipeline completo: Spider ‚Üí Play ‚Üí Banco de dados
- Conectividade com PostgreSQL e MinIO
- Valida√ß√£o de comandos Makefile

**3. Testes End-to-End (Playwright)**

- Simula√ß√£o de navega√ß√£o real nos portais
- Testes com browsers automatizados (Firefox)
- Valida√ß√£o de JavaScript e conte√∫do din√¢mico

#### Crit√©rios de Qualidade para Testes

- **Cobertura m√≠nima**: Todos os novos scrapers devem incluir testes
- **URLs reais**: Testes devem usar URLs fornecidas nas issues
- **Valida√ß√£o dos 4 campos**: T√≠tulo, descri√ß√£o, corpo e tags
- **Testes de regress√£o**: Garantir que adapta√ß√µes n√£o quebrem funcionalidades existentes

### Ferramentas de CI/CD

#### Pipeline de Integra√ß√£o Cont√≠nua

O projeto utiliza **GitHub Actions** com workflow automatizado executado em:

- Push para branches `main` e `develop`
- Abertura de Pull Requests

#### Jobs do Pipeline

**1. Lint (Python)**

```yaml
- Flake8 para verifica√ß√£o de c√≥digo Python
- Valida√ß√£o de erros cr√≠ticos (E9, F63, F7, F82)
- Verifica√ß√£o de complexidade e comprimento de linha
```

**2. Backend (FastAPI)**

```yaml
- Lint espec√≠fico do backend
- Healthcheck do servidor Uvicorn
- Valida√ß√£o de endpoints (/ping)
```

**3. Frontend (React + Vite)**

```yaml
- Setup Node.js 20 com pnpm
- Lint com Biome
- Build de produ√ß√£o
```

**4. Testes Docker**

```yaml
- PostgreSQL 16 para testes de banco
- MinIO para armazenamento (descontinuado mas mantido para compatibilidade)
- Playwright com Firefox para testes E2E
- Execu√ß√£o completa da suite de testes
```

**5. Build Docker**

```yaml
- Valida√ß√£o de build da imagem Docker
- Cache otimizado com GitHub Actions
- Teste de execu√ß√£o da imagem
```

#### Valida√ß√µes Obrigat√≥rias

Todos os Pull Requests devem:

- ‚úÖ Passar em todos os jobs de CI
- ‚úÖ Ter pelo menos 1 reviewer aprovado
- ‚úÖ Seguir conven√ß√µes de branch e commit
- ‚úÖ Incluir testes para novas funcionalidades
- ‚úÖ Manter compatibilidade com vers√µes existentes

#### Estrat√©gias de Merge

- **Squash & Merge**: Para `feature/*`, `bugfix/*` e `doc/*`
- **Merge commit**: Para `release/*` e `hotfix/*` (preservando hist√≥rico de versionamento)
- **Tags autom√°ticas**: Aplicadas na branch `main` seguindo Semantic Versioning

### Monitoramento de Qualidade

#### M√©tricas Acompanhadas

- **Taxa de sucesso do CI**: Percentual de builds bem-sucedidos
- **Tempo de execu√ß√£o**: Otimiza√ß√£o cont√≠nua do pipeline
- **Cobertura de testes**: Especialmente para novos scrapers
- **Regress√µes**: Detec√ß√£o precoce de quebras em scrapers existentes

#### Ferramentas de Apoio

- **GitHub Actions**: Automa√ß√£o de CI/CD
- **Pytest**: Framework de testes Python
- **Playwright**: Testes automatizados de browser
- **Docker**: Containeriza√ß√£o e testes de ambiente
- **PostgreSQL**: Valida√ß√£o de persist√™ncia de dados

## Contato

### Documenta√ß√£o

A documenta√ß√£o completa do projeto CheckUp e demais projetos da organiza√ß√£o pode ser encontrada em:

**üîó [https://eh-fake.github.io/docs/land/index.html](https://eh-fake.github.io/docs/land/index.html)**

#### Issues e Discuss√µes

O principal canal de comunica√ß√£o da comunidade √© atrav√©s das **Issues do GitHub**, onde:

- ‚úÖ Reportar bugs utilizando templates espec√≠ficos
- ‚úÖ Solicitar novas funcionalidades
- ‚úÖ Propor melhorias e adapta√ß√µes
- ‚úÖ Esclarecer d√∫vidas t√©cnicas
- ‚úÖ Participar de discuss√µes sobre o projeto

#### Para Novos Contribuidores

1. **Consulte a documenta√ß√£o** oficial antes de iniciar
2. **Leia os tutoriais** espec√≠ficos para seu tipo de contribui√ß√£o
3. **Abra uma issue** seguindo os templates dispon√≠veis
4. **Participe das discuss√µes** em Pull Requests existentes para aprender

#### Para Quest√µes T√©cnicas

- **Problemas com scrapers**: Consulte exemplos existentes (`gazetaDoPovo.py`, `metropoles.py`)
- **D√∫vidas sobre implementa√ß√£o**: Verifique a documenta√ß√£o das classes base (`BaseSpider`, `BasePlay`)
- **Erros de setup**: Consulte os tutoriais de instala√ß√£o e configura√ß√£o

### Links √öteis

- **Documenta√ß√£o Principal**: https://eh-fake.github.io/docs/land/index.html
- **Reposit√≥rio CheckUp**: [Link do reposit√≥rio principal]
- **Templates de Issues**: Dispon√≠veis no reposit√≥rio GitHub
- **Tutoriais Espec√≠ficos**:
  - `TUTORIAL_CRIACAO_DO_ZERO.md`
  - `TUTORIAL_SPIDERS_PLAYS.md`
